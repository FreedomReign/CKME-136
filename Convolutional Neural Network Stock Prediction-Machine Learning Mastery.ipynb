{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as dr\n",
    "from datetime import datetime\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from scipy import misc\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=datetime(2015,1,1)\n",
    "end=datetime(2019,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>27913900.0</td>\n",
       "      <td>42.418739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>46.730000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>46.369999</td>\n",
       "      <td>46.330002</td>\n",
       "      <td>39673900.0</td>\n",
       "      <td>42.028660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>46.750000</td>\n",
       "      <td>45.540001</td>\n",
       "      <td>46.380001</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>36447900.0</td>\n",
       "      <td>41.411785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>46.459999</td>\n",
       "      <td>45.490002</td>\n",
       "      <td>45.980000</td>\n",
       "      <td>46.230000</td>\n",
       "      <td>29114100.0</td>\n",
       "      <td>41.937946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>47.750000</td>\n",
       "      <td>46.720001</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>47.590000</td>\n",
       "      <td>29645200.0</td>\n",
       "      <td>43.171677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High        Low       Open      Close      Volume  Adj Close\n",
       "Date                                                                         \n",
       "2015-01-02  47.419998  46.540001  46.660000  46.759998  27913900.0  42.418739\n",
       "2015-01-05  46.730000  46.250000  46.369999  46.330002  39673900.0  42.028660\n",
       "2015-01-06  46.750000  45.540001  46.380001  45.650002  36447900.0  41.411785\n",
       "2015-01-07  46.459999  45.490002  45.980000  46.230000  29114100.0  41.937946\n",
       "2015-01-08  47.750000  46.720001  46.750000  47.590000  29645200.0  43.171677"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tesla = web.DataReader('TSLA', 'google', start,end)\n",
    "microsoft = dr.data.get_data_yahoo('MSFT', start=start, end=end)\n",
    "\n",
    "dataset = microsoft\n",
    "close_data = microsoft['Close']\n",
    "dates = pd.DataFrame(close_data.index)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      " > 3.881\n",
      " > 1.896\n",
      " > 3.296\n",
      " > 2.073\n",
      " > 2.614\n",
      " > 1.844\n",
      " > 4.332\n",
      " > 2.919\n",
      " > 1.735\n",
      " > 4.479\n",
      " > 3.818\n",
      " > 5.129\n",
      " > 2.947\n",
      " > 3.287\n",
      " > 2.452\n",
      " > 3.417\n",
      " > 2.415\n",
      " > 2.880\n",
      " > 1.752\n",
      " > 1.621\n",
      " > 1.922\n",
      " > 1.666\n",
      " > 2.016\n",
      " > 3.090\n",
      " > 3.440\n",
      " > 2.891\n",
      " > 3.700\n",
      " > 2.492\n",
      " > 2.011\n",
      " > 3.422\n",
      "cnn: 2.848 RMSE (+/- 0.911)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate cnn\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_filters, n_kernel, n_epochs, n_batch = config\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, 1)))\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, _ = config\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = dataset['Close']\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 12\n",
    "# define config\n",
    "config = [36, 256, 3, 100, 100]\n",
    "#n_input, n_filters, n_kernel, n_epochs, n_batch\n",
    "\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('cnn', scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
