{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Solution adapted from Kris C Naik\n",
    "#GitHub https://github.com/krishnaik06/Stock-Price-Prediction-using-Keras-and-Recurrent-Neural-Networ/blob/master/rnn.py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import autocorrelation_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as dr\n",
    "from datetime import datetime\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=datetime(2015,1,1)\n",
    "end=datetime(2019,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 High        Low       Open      Close      Volume  Adj Close\n",
      "Date                                                                         \n",
      "2015-01-02  47.419998  46.540001  46.660000  46.759998  27913900.0  42.418739\n",
      "2015-01-05  46.730000  46.250000  46.369999  46.330002  39673900.0  42.028660\n",
      "2015-01-06  46.750000  45.540001  46.380001  45.650002  36447900.0  41.411785\n",
      "2015-01-07  46.459999  45.490002  45.980000  46.230000  29114100.0  41.937946\n",
      "2015-01-08  47.750000  46.720001  46.750000  47.590000  29645200.0  43.171677\n",
      "[[ 46.75999832]\n",
      " [ 46.33000183]\n",
      " [ 45.65000153]\n",
      " ...\n",
      " [117.94000244]\n",
      " [119.01999664]\n",
      " [119.19000244]]\n"
     ]
    }
   ],
   "source": [
    "# tesla = web.DataReader('TSLA', 'google', start,end)\n",
    "microsoft = dr.data.get_data_yahoo('MSFT', start=start, end=end)\n",
    "\n",
    "dataset = microsoft\n",
    "\n",
    "training_set = dataset.iloc[:, 3:4].values\n",
    "print(dataset.head())\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "1006\n"
     ]
    }
   ],
   "source": [
    "# Creating a data structure with 63 (approx. 1 quarter) timesteps and 1 output (next day value)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(63, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-63:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "print(X_train.shape[0])\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "#https://keras.io/layer/recurrent\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense #output layer\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout #for each Epox deactivate those that result in 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 18s 18ms/step - loss: 0.1212\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0218\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0093\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0052\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0042\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 5s 4ms/step - loss: 0.0041\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.0035\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.0041\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.0038\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0036\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0036\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0034\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0030\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0029\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0034\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0029\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0031\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0032\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 8s 8ms/step - loss: 0.0033\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0034\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0031\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0031\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 7s 6ms/step - loss: 0.0028\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0028\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0028\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0029\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0028\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0030\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.0030\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200f9d33860>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 30, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-2d0dab216159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Visualising the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_stock_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Real Stock Price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Predicted Stock Price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3345\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_autogen_docstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3346\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3347\u001b[1;33m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3348\u001b[0m     \u001b[1;31m# Deprecated: allow callers to override the hold state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3349\u001b[0m     \u001b[1;31m# by passing hold=True|False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mgca\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mgca\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     \"\"\"\n\u001b[1;32m--> 984\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[1;31m# More ways of creating axes:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mgcf\u001b[1;34m()\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfigManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# Setting Real stock price\n",
    "real_stock_price = test_data\n",
    "\n",
    "# Getting the predicted stock price\n",
    "dataset_total = dataset['Close']\n",
    "inputs = dataset_total[len(dataset_total) - len(test_data) - 63:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(63, 380):\n",
    "    X_test.append(inputs[i-63:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "# Visualising the results\n",
    "plt.plot(1,1)\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Stock Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates = [dataset.index[-1] + DateOffset(days=x) for x in range(1,365)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_2_input to have 3 dimensions, but got array with shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ef724e7090ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture_dates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfuture_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forecast'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture_dates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_2_input to have 3 dimensions, but got array with shape ()"
     ]
    }
   ],
   "source": [
    "x = np.array(future_dates.index)\n",
    "\n",
    "future_dates['forecast'] = regressor.predict(np.array(future_dates.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model, fit and plot data using regressor calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46.65999985]\n",
      " [ 46.36999893]\n",
      " [ 46.38000107]\n",
      " ...\n",
      " [118.06999969]\n",
      " [118.94999695]\n",
      " [119.05999756]]\n",
      "1069\n"
     ]
    }
   ],
   "source": [
    "# Prolog - Auto Generated #\n",
    "import os, matplotlib.pyplot, uuid, pandas\n",
    "\n",
    "# dataset.sort_values(by=['date'], inplace=True, ascending=True)\n",
    "# dataset['date'] = pandas.to_datetime(dataset['date'])\n",
    "# dataset.set_index(\"date\", inplace = True)\n",
    "\n",
    "model_dataset = dataset.iloc[:, 2:3].values \n",
    "\n",
    "# dataset = pandas.DataFrame(date, Close, Gain, ema, Volume, sma_10, sma_20, sma_50, sma_100, rsi)\n",
    "# dataset = dataset.drop_duplicates()\n",
    "print(model_dataset)\n",
    "print(len(model_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46.65999985 46.36999893 46.38000107 45.97999954 46.75       47.61000061\n",
      "  47.41999817 46.97000122 45.95999908 46.22000122 45.31000137 46.29999924\n",
      "  45.93999863 46.38000107 47.36000061 47.         42.95000076 42.74000168\n",
      "  40.93000031 41.54999924 40.59000015 41.63000107 41.93999863 42.22000122\n",
      "  42.68000031 42.24000168 42.74000168 42.65000153 42.65999985 43.38000107\n",
      "  43.97000122 43.63000107 43.18000031 43.50999832 43.70000076 44.15000153\n",
      "  43.95000076 43.99000168 44.13000107 43.66999817 43.56000137 43.00999832\n",
      "  43.06999969 43.         42.18999863 42.34999847 42.31000137 41.33000183\n",
      "  40.70000076 41.47000122 41.36999893 41.43000031 42.25999832 42.56000137\n",
      "  42.88000107 42.77999878 42.91999817 41.22000122 41.11999893 41.09999847\n",
      "  40.77999878 40.59999847 40.65999985 40.34000015 41.61000061 41.45999908\n",
      "  41.25       41.63000107 41.40000153 41.79999924 41.75999832 41.95000076\n",
      "  41.66999817 41.72999954 43.         42.66999817 42.88999939 45.65999985\n",
      "  47.22999954 47.77999878 48.72000122 48.70000076 48.58000183 48.36999893\n",
      "  47.81999969 47.56999969 46.27000046 47.54999924 47.54999924 46.84999847\n",
      "  48.18999863 48.02999878 48.86999893 47.97999954 47.56000137 47.38999939\n",
      "  47.27999878 47.29999924 46.83000183 46.81999969 47.5        47.43000031\n",
      "  47.06000137 46.93000031 47.36999893 46.79000092 46.31000137 46.29999924\n",
      "  45.75999832 45.79000092 46.65999985 46.22000122 45.45000076 45.34999847\n",
      "  45.72999954 46.22000122 46.79000092 46.33000183 46.13000107 45.66999817\n",
      "  46.02999878 45.65000153 45.04000092 44.70999908 44.45999908 44.47999954\n",
      "  43.95999908 44.34000015 44.43999863 44.75       45.00999832 44.97999954\n",
      "  45.45000076 45.68000031 46.00999832 46.54999924 46.65000153 46.77999878\n",
      "  45.43999863 45.27000046 45.90999985 45.93999863 45.58000183 45.40000153\n",
      "  46.25999832 47.29000092 46.97999954 46.75       47.97999954 47.70999908\n",
      "  46.38999939 46.95000076 46.81999969 46.18999863 47.06000137 46.52999878\n",
      "  46.81000137 46.84000015 46.77999878 46.06999969 45.29999924 40.45000076\n",
      "  42.56999969 42.00999832 43.22999954 43.40000153 43.56000137 42.16999817\n",
      "  42.36000061 43.40999985 42.81000137 43.29999924 44.20999908 43.11999893\n",
      "  43.13999939 43.43000031 43.18999863 43.97000122 44.29000092 43.5\n",
      "  43.61999893 43.38000107 43.93000031 43.45000076 44.47999954 43.83000183\n",
      "  43.36999893 43.88000107 44.75       44.27000046 45.75       46.33000183\n",
      "  47.09999847 46.56000137 47.45000076 46.97999954 46.56000137 46.65000153\n",
      "  47.00999832 47.02000046 47.41999817 47.43999863 47.91999817 47.52999878\n",
      "  52.29999924 52.52999878 53.99000168 53.54000092 53.54000092 53.31999969\n",
      "  52.84999847 52.93000031 54.18000031 54.49000168 54.09000015 54.54999924\n",
      "  54.06999969 53.70000076 53.47999954 53.06999969 53.08000183 53.16999817\n",
      "  53.         53.99000168 54.25       54.25       53.91999817 54.09000015\n",
      "  53.79999924 54.54000092 54.40999985 55.31999969 55.49000168 54.11999893\n",
      "  55.79000092 55.47000122 55.36999893 55.38999939 54.70999908 54.33000183\n",
      "  55.65999985 55.54000092 56.36000061 55.77000046 54.88000107 54.99000168\n",
      "  55.70000076 55.86000061 55.34999847 56.29000092 56.47000122 56.04000092\n",
      "  54.31999969 54.93000031 54.31999969 52.70000076 52.36999893 52.50999832\n",
      "  52.75999832 53.79999924 52.         51.31000137 51.47999954 49.97999954\n",
      "  51.         51.40999985 51.93999863 51.79000092 52.00999832 51.86000061\n",
      "  54.72999954 54.88000107 54.16999817 53.25       52.09999847 51.93999863\n",
      "  49.54999924 49.02000046 49.88999939 48.68000031 50.25       50.90000153\n",
      "  51.49000168 52.33000183 51.97000122 52.27999878 52.34000015 50.68999863\n",
      "  51.72999954 52.59999847 51.34999847 50.97000122 52.40999985 52.97000122\n",
      "  52.40000153 51.56000137 50.79999924 51.88999939 52.93000031 53.\n",
      "  52.70999908 52.75       53.45000076 54.20999908 54.91999817 53.25\n",
      "  53.61000061 54.11000061 53.84000015 54.20999908 53.65999985 54.93000031\n",
      "  54.95000076 55.04999924 55.43000031 55.18999863 54.36000061 54.86999893\n",
      "  54.66999817 54.49000168 54.36999893 55.11999893 55.22000122 55.29999924\n",
      "  55.49000168 56.63000107 56.29000092 55.79999924 51.90999985 51.77999878\n",
      "  52.25999832 51.47999954 50.61999893 49.34999847 50.         50.34000015\n",
      "  49.84000015 49.86999893 49.91999817 50.49000168 50.33000183 51.13000107\n",
      "  51.20000076 51.43999863 50.79999924 51.72000122 50.47999954 50.47000122\n",
      "  50.47999954 50.59999847 50.70000076 51.91999817 51.93000031 51.91999817\n",
      "  52.25999832 52.43999863 52.63999939 52.38000107 51.99000168 52.24000168\n",
      "  52.02000046 52.         51.04999924 49.58000183 49.90000153 49.77999878\n",
      "  49.52000046 50.40999985 50.63999939 50.20000076 51.08000183 51.27999878\n",
      "  49.81000137 49.09999847 48.91999817 49.90999985 50.72000122 51.13000107\n",
      "  50.83000183 50.77999878 51.41999817 51.72999954 52.5        52.93999863\n",
      "  53.56000137 53.84000015 53.95000076 53.70000076 53.70999908 56.15000153\n",
      "  55.97999954 56.08000183 56.47000122 56.52000046 56.61000061 56.\n",
      "  56.25999832 56.59999847 56.84999847 56.68000031 56.79999924 57.65000153\n",
      "  58.06000137 58.16999817 58.15999985 58.02999878 58.02999878 58.00999832\n",
      "  57.61000061 57.54000092 57.41999817 57.43000031 57.59999847 57.90000153\n",
      "  57.79999924 57.88000107 58.27999878 58.18000031 57.97999954 57.65000153\n",
      "  57.00999832 57.66999817 57.77999878 57.47000122 57.63000107 56.79000092\n",
      "  56.         56.5        56.38999939 56.15000153 57.63000107 57.27000046\n",
      "  57.34999847 57.50999832 57.91999817 57.86999893 57.08000183 56.93000031\n",
      "  57.88000107 57.81000137 57.56999969 57.40999985 57.27000046 57.29000092\n",
      "  57.74000168 57.84999847 57.90999985 57.88999939 57.11000061 56.70000076\n",
      "  57.11999893 57.36000061 57.52999878 57.47000122 57.5        60.27999878\n",
      "  59.93999863 60.84999847 60.81000137 60.61000061 60.00999832 60.15999985\n",
      "  59.97000122 59.81999969 59.52999878 58.65000153 59.77999878 60.54999924\n",
      "  60.         60.47999954 58.22999954 59.02000046 58.33000183 58.93999863\n",
      "  60.40999985 60.77999878 60.5        60.97999954 61.00999832 60.29999924\n",
      "  60.34000015 60.65000153 60.86000061 60.11000061 59.08000183 59.70000076\n",
      "  60.43000031 60.00999832 61.29999924 61.18000031 61.81999969 62.5\n",
      "  63.         62.70000076 62.95000076 62.56000137 63.68999863 63.43000031\n",
      "  63.84000015 63.45000076 63.20999908 63.40000153 62.86000061 62.95999908\n",
      "  62.79000092 62.47999954 62.18999863 62.29999924 62.75999832 62.72999954\n",
      "  62.61000061 63.06000137 62.61999893 62.68000031 62.66999817 62.24000168\n",
      "  62.66999817 62.70000076 63.20000076 63.95000076 64.12000275 65.38999939\n",
      "  65.69000244 64.86000061 64.36000061 63.25       63.5        63.5\n",
      "  63.74000168 63.56999969 63.52000046 64.25       64.23999786 64.41000366\n",
      "  64.5        64.73999786 64.47000122 64.61000061 64.33000183 64.41999817\n",
      "  64.52999878 64.54000092 64.08000183 64.12999725 64.69000244 63.99000168\n",
      "  63.97000122 64.19000244 64.26000214 65.19000244 65.11000061 65.01000214\n",
      "  64.52999878 64.55000305 64.75       64.91000366 64.91000366 65.19000244\n",
      "  64.12000275 64.94000244 65.36000061 64.62999725 64.95999908 65.12000275\n",
      "  65.41999817 65.65000153 65.80999756 65.38999939 66.30000305 65.59999847\n",
      "  65.84999847 65.61000061 65.59999847 65.41999817 65.29000092 65.04000092\n",
      "  65.33000183 65.65000153 65.45999908 65.66999817 67.48000336 67.90000153\n",
      "  68.08000183 68.15000153 68.91000366 68.68000031 69.70999908 69.37999725\n",
      "  69.02999878 68.90000153 68.97000122 68.86000061 68.98999786 68.36000061\n",
      "  68.61000061 68.13999939 68.23000336 68.88999939 67.40000153 67.5\n",
      "  67.88999939 68.72000122 68.87000275 68.97000122 69.80000305 69.79000092\n",
      "  70.52999878 70.23999786 70.44000244 71.97000122 72.30000305 72.63999939\n",
      "  72.51000214 72.04000092 69.25       70.01999664 70.91000366 69.26999664\n",
      "  69.73000336 70.5        70.81999969 70.20999908 70.54000092 70.08999634\n",
      "  71.40000153 70.11000061 69.20999908 69.37999725 68.77999878 69.33000183\n",
      "  68.26000214 68.26999664 68.69999695 69.45999908 70.         70.69000244\n",
      "  71.5        72.23999786 72.80000305 73.08999634 73.5        74.18000031\n",
      "  73.44999695 73.52999878 73.80000305 74.33999634 73.76000214 72.66999817\n",
      "  73.30000305 73.09999847 72.55000305 72.19000244 72.40000153 72.80000305\n",
      "  72.08999634 72.25       71.90000153 71.61000061 73.05999756 73.58999634\n",
      "  73.33999634 73.58000183 72.26999664 72.47000122 72.34999847 72.95999908\n",
      "  72.73999786 72.86000061 73.05999756 72.25       73.01000214 74.02999878\n",
      "  74.70999908 73.33999634 73.73999786 73.68000031 74.33000183 74.30999756\n",
      "  74.76000214 74.93000031 75.         74.83000183 75.23000336 75.20999908\n",
      "  75.34999847 75.11000061 73.98999786 74.08999634 73.66999817 73.55000305\n",
      "  73.54000092 73.94000244 74.70999908 74.66999817 74.08999634 75.22000122\n",
      "  75.66999817 75.97000122 76.33000183 76.36000061 76.48999786 77.58999634\n",
      "  77.41999817 77.47000122 77.66999817 77.56999969 78.31999969 78.98999786\n",
      "  78.90000153 78.58000183 79.19999695 84.37000275 83.69999695 84.36000061\n",
      "  83.68000031 83.34999847 84.08000183 84.19999695 84.76999664 84.13999939\n",
      "  84.11000061 83.79000092 83.66000366 83.5        83.47000122 83.09999847\n",
      "  83.12000275 82.40000153 82.73999786 83.83000183 83.01000214 83.30999756\n",
      "  84.06999969 84.70999908 83.51000214 83.59999847 84.41999817 81.33999634\n",
      "  81.55000305 82.54000092 83.62999725 84.29000092 85.30999756 85.73999786\n",
      "  85.43000031 85.26000214 87.12000275 86.34999847 86.19999695 86.05000305]]\n",
      "319\n"
     ]
    }
   ],
   "source": [
    " # First calculate the mid prices from the highest and lowest\n",
    "\n",
    "train_data = model_dataset[:750]\n",
    "test_data = model_dataset[750:]\n",
    "\n",
    "print(train_data.transpose())\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to be between 0 and 1\n",
    "# When scaling remember! You normalize both test and train data with respect to training data\n",
    "# Because you are not supposed to have access to test data\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
