{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Solution adapted from Kris C Naik\n",
    "#GitHub https://github.com/krishnaik06/Stock-Price-Prediction-using-Keras-and-Recurrent-Neural-Networ/blob/master/rnn.py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers import Dense\n",
    "\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as dr\n",
    "from datetime import datetime\n",
    "import pandas_datareader.data as web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=datetime(2015,1,1)\n",
    "end=datetime(2019,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tesla = web.DataReader('TSLA', 'google', start,end)\n",
    "microsoft = dr.data.get_data_yahoo('MSFT', start=start, end=end)\n",
    "\n",
    "dataset = microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    values = list()\n",
    "    for offset in config:\n",
    "        values.append(history[-offset])\n",
    "    return median(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will have an input layer with some number of prior observations. This can be specified using the input_dim argument when we define the first hidden layer. The model will have a single hidden layer with some number of nodes, then a single output layer.\n",
    "\n",
    "We will use the rectified linear activation function on the hidden layer as it performs well. We will use a linear activation function (the default) on the output layer because we are predicting a continuous value.\n",
    "\n",
    "The loss function for the network will be the mean squared error loss, or MSE, and we will use the efficient Adam flavor of stochastic gradient descent to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=63))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch = config\n",
    "    print(config)\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    print(config)\n",
    "    # unpack config\n",
    "    n_input, _, _, _ = config\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape(1, n_input)\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config=[63,500,64,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > 3.595\n",
      " > 3.357\n",
      " > 3.027\n",
      " > 2.787\n",
      " > 2.838\n",
      " > 2.942\n",
      " > 3.360\n",
      " > 3.047\n",
      " > 2.994\n",
      " > 2.884\n",
      " > 4.736\n",
      " > 2.841\n",
      " > 2.813\n",
      " > 3.583\n",
      " > 3.316\n"
     ]
    }
   ],
   "source": [
    "# evaluate mlp\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch = config\n",
    "    # prepare data\n",
    "    data = series_to_supervised(train, n_in=n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _ = config\n",
    "    # prepare data\n",
    "    x_input = array(history[-n_input:]).reshape(1, n_input)\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "    return yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    \n",
    "    print(' > %.3f' % error)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, config, n_test, n_repeats=30):\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(n_repeats)]\n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(name, scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print('%s: %.3f RMSE (+/- %.3f)' % (name, scores_m, score_std))\n",
    "\n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "series = dataset['Close']\n",
    "data = series.values\n",
    "# data split\n",
    "n_test = 200\n",
    "# define config\n",
    "config = [63, 500, 100, 100]\n",
    "#n_input, n_nodes, n_epochs, n_batch\n",
    "\n",
    "# grid search\n",
    "scores = repeat_evaluate(data, config, n_test)\n",
    "# summarize scores\n",
    "summarize_scores('mlp', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
